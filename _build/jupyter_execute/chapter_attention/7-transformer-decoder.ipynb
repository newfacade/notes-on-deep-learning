{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Decoder\n",
    "\n",
    "```{note}\n",
    "本节我们使用之前介绍过的组件来搭建 Transformer Decoder.\n",
    "```\n",
    "\n",
    "![jupyter](../images/attention/transformer.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器 Block\n",
    "\n",
    "如结构图所示，Transformer的解码器也是由多个结构相同的层组成。\n",
    "\n",
    "`DecoderBlock`包含三个子层：解码器自注意力、\"编码器-解码器\"注意力和基于位置的前馈网络。\n",
    "\n",
    "在遮蔽多头自注意力层（Masked multi-head attention，第一层）中，查询、键和值都来自于上一个解码器层的输出。在训练阶段，输出序列所有时间步的词元都是已知的；然而，在预测阶段，其输出序列的词元是逐个生成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import d2l\n",
    "import math\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中的第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_hiddens, num_heads, \n",
    "                 dropout, i):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.i = i\n",
    "        self.attention1 = d2l.MultiHeadAttention(key_size, query_size,\n",
    "                                                 value_size, num_hiddens,\n",
    "                                                 num_heads, dropout)\n",
    "        self.addnorm1 = d2l.AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = d2l.MultiHeadAttention(key_size, query_size,\n",
    "                                                 value_size, num_hiddens,\n",
    "                                                 num_heads, dropout)\n",
    "        self.addnorm2 = d2l.AddNorm(norm_shape, dropout)\n",
    "        self.ffn = d2l.PositionWiseFFN(num_hiddens, ffn_num_hiddens)\n",
    "        self.addnorm3 = d2l.AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 训练阶段 `X` shape: (`batch_size`, `num_steps`, `num_hiddens`)\n",
    "        # 预测阶段 `X` shape: (`batch_size`, 1, `num_hiddens`)\n",
    "        # enc_outputs来自编码器（即其最后一个编码器block的输出）shape (`batch_size`, `num_steps`, `num_hiddens`)\n",
    "        # enc_valid_lens也来编码器\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        \n",
    "        # `state[2][self.i]` 用于预测阶段，初始化为None，它存储截止目前时间步的的输出序列\n",
    "        # 训练和第一个token的预测\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        # 后续预测\n",
    "        else:\n",
    "            # 跟RNN-seq2seq不一样，Transformer预测要用到截止目前的输出序列，而不只是上一时间步的输出\n",
    "            # key_values shape: (`batch_size`, `cur_steps`, `num_hiddens`)\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        \n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # 防作弊\n",
    "            # shape of dec_valid_lens: (`batch_size`, `num_steps`)\n",
    "            # 其中每一行是 [1, 2, ..., `num_steps`]\n",
    "            dec_valid_lens = torch.arange(1, num_steps + 1, \n",
    "                                          device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            # 预测时token by token就不用了\n",
    "            dec_valid_lens = None\n",
    "        \n",
    "        # Self-attention\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # Encoder-decoder attention\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.Decoder):\n",
    "    \"\"\"Transformer解码器\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, \n",
    "                 norm_shape, ffn_num_hiddens, num_heads, \n",
    "                 num_layers, dropout):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        # 各个DecoderBlock\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                \"block\" + str(i),\n",
    "                DecoderBlock(num_hiddens, num_hiddens, num_hiddens, num_hiddens,\n",
    "                             norm_shape, ffn_num_hiddens, num_heads, \n",
    "                             dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # 给state[2]留位置\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 常规操作\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            # state[0]和state[1]存储编码器的信息\n",
    "            # state[2]用于预测，用来存储截止目前时间步各个block的输出序列\n",
    "            X, state = blk(X, state)\n",
    "        return self.dense(X), state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}