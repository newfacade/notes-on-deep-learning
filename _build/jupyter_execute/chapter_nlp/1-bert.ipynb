{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732393b1-a3d9-4ff0-a959-c7453e63a70e",
   "metadata": {},
   "source": [
    "# BERT\n",
    "\n",
    "论文: https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce46bbcd-012d-40fe-808e-8d134c0d54b4",
   "metadata": {},
   "source": [
    "## 训练方式\n",
    "\n",
    "BERT 采用预训练 + 微调的方式。\n",
    "\n",
    "因为大多数 NLP 任务的输入为一个句子或者两个句子，所以 BERT 的输入是两个句子，句子间用 [SEP] 分隔，句子开头是特殊字符 [CLS]。\n",
    "\n",
    "![](../images/nlp/bert1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ac917-6b4c-4c78-bc4e-41cd8570a0c6",
   "metadata": {},
   "source": [
    "## 模型\n",
    "\n",
    "BERT 模型使用 Transformer Encoder，跟标准 Transformer Encoder 的区别在于它使用了可学习的 Position Embeddings + Segment Embeddings（用于标识当前 token 在第一句话还是第二句话）。\n",
    "\n",
    "![](../images/nlp/bert2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bcb874-939a-4805-9426-e86bdc4cdc03",
   "metadata": {},
   "source": [
    "## 预训练任务\n",
    "\n",
    "### Masked LM\n",
    "In order to train a deep bidirectional representation, we simply mask some percentage of the input tokens as random, and predict those masked tokens [MASK]. （即完形填空）\n",
    "\n",
    "微调时输入是没有 [MASK] 的，为了使模型在预训练时见过微调时的分布，BERT对遮蔽的token做了如下处理：\n",
    "\n",
    "1. [MASK] token 80% of the time\n",
    "2. a random token 10% of the time\n",
    "3. the unchanged token 10% of the time\n",
    "\n",
    "### Next Sentence Prediction\n",
    "\n",
    "Many important downstream tasks such as Question Answering (QA) and Natural Language Inference(NLI) are based on understanding the relationship between two sentences, which is not directly captured by language modeling.\n",
    "\n",
    "BERT 训练了 Next Sentence Prediction 二分类模型，训练集中 50% 是正例，50% 是负例，模型使用 [CLS] 的输出做预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3933b-948b-499b-a187-00b5af05cd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}